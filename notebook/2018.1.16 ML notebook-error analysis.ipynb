{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018.1.16 Notebook \n",
    "李曦嵘　　634602068@qq.com　　武汉大学电子信息学院\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Learning curves\n",
    "\n",
    "Learning curves:\n",
    "\n",
    "\\begin{align}\n",
    "J_{train}(\\theta)&=\\frac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}-y^{(i)})^2  \\tag1\\\n",
    "\\end{align}\n",
    "\n",
    "Cross validation error:\n",
    "\\begin{align}\n",
    "J_{cv}(\\theta)&=\\frac{1}{2m_{cv}}\\sum_{i=1}^m(h_{\\theta}(x_{cv}^{(i)}-y_{cv}^{(i)})^2  \\tag2\\\n",
    "\\end{align}\n",
    "\n",
    "High bias（模型欠拟合）的情况：  \n",
    "<img src=\"http://img.blog.csdn.net/20170518224030919?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" >  \n",
    "随着样本数量$m$的增加（$0 \\to \\infty$），训练误差由$0$逐渐增大，交叉验证误差由$\\infty$逐渐减小，最终二者趋于一个较大的稳定值，$J_{train}(\\theta) \\approx J_{cv}(\\theta)$。  \n",
    "这意味着，如果一个学习算法有着较大的误差，那么当样本数量已经足够多时，增加样本数量对于减小误差没有影响。  \n",
    "\n",
    "High variance（模型过拟合）的情况：  \n",
    "<img src=\"http://img.blog.csdn.net/20170518224341002?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" >  \n",
    "\n",
    "在训练误差和交叉验证误差之间存在较大的gap，但增加样本数量会使交叉验证误差逐渐减小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 Deciding what to do next\n",
    "\n",
    "Debugging a learning algorithm:\n",
    " - Get more training examples —— $ \\text{fix high variance} $ \n",
    " - Try smaller sets of features ——  $ \\text{fix high variance} $\n",
    " - Try getting additional features —— $ \\text{fix high bias} $\n",
    " - Try adding polynomial features  —— $ \\text{fix high bias} $\n",
    " - Try decreasing $\\lambda$ —— $ \\text{fix high bias} $\n",
    " - Try increasing $\\lambda$ —— $ \\text{fix high variance} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Machine learning system design\n",
    "\n",
    "## 11.1 Spam classification example\n",
    "\n",
    "以做一个垃圾邮件分类器为例。  \n",
    "我们需要寻找最频繁出现出现的n个单词（10000~50000）作为训练集，而不是随意手工寻找100个单词。\n",
    "\n",
    "下面的做法帮助你改善你的模型：  \n",
    "- 收集大量的数据。 eg. “honeypot”项目。\n",
    "- 从邮件信息中找寻复杂的特征（例如从邮件首部）。\n",
    "- 从邮件体中找寻复杂的特征（discount 和discounts是否被对待一致，关于标点符号的特征）。\n",
    "- 使用复杂的算法来检测邮件中的拼写错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Error analysis\n",
    "\n",
    "对误差的分析：  \n",
    "- 先开始一个简单算法使你能快速实现它，在你的交叉验证集上测试它。\n",
    "- 画出学习曲线来判断是否更多的数据，更多的特征有助于改进算法。\n",
    "- 误差分析，在交叉验证集上检测你的算法，发现错误在某种类样本上出现的趋势。\n",
    "\n",
    "将误差转变为一个单一的数值非常重要，否则很难判断我们所设计的学习算法的表现。  \n",
    "在误差分析中我们应使用定量计算来评判算法的表现。\n",
    "<img src=\"http://img.blog.csdn.net/20170519213636007?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Error metrics for skewed classes（倾斜类的错误指标）\n",
    "\n",
    "以判断癌症的分类器为例。  \n",
    "建立逻辑回归模型$h_{\\theta}(x)$，$y=1$表示有癌症，$y=0$则没有。  \n",
    "假设你的算法在测试集上只有1%的错误率，可实际上，测试集中只有0.5%的病人患有癌症，那么下图所示的非机器学习方法与机器学习方法具有相同的错误率（$0.5\\%$）。    \n",
    "<img src=\"http://img.blog.csdn.net/20170519214455499?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" >  \n",
    "像这种，样本中$y=1$的样本数目远小于$y=0$样本数目（或相反）的情况叫做skewed classes（倾斜类）。  \n",
    "从上面的例子我们可以知道正确率不足以表现一个算法的优劣（在某些正例或反例及其少的数据集中），因此我们引入了Precision/Recall。  \n",
    "\n",
    "<img src=\"http://img.blog.csdn.net/20170519215310718?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjcwMDgwNzk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\"  >\n",
    "\n",
    "TP：真正例；FP：假正例；TN：真反例；FN：假反例。  \n",
    "\n",
    "**Accuracy（正确率） **\n",
    "在我们预测y=1和y=0的数据中，预测正确的比重。  \n",
    "$$\n",
    "\\frac{预测正确的样本数}{总样本数} = \\frac{True　pos + False neg}{True　pos + False　pos + Ture neg + False neg} \\tag3\n",
    "$$\n",
    "\n",
    "**Precision（准确率）**  \n",
    "在我们预测y=1的数据中，真正得癌症的比重。   \n",
    "$$\n",
    "\\frac{True　pos}{predicted　pos} = \\frac{True　pos}{True　pos+ False　pos} \\tag4\n",
    "$$\n",
    "\n",
    "**Recal（召回率）**  \n",
    "在真正得癌症的数据中，我们预测癌症所占的比重。  \n",
    "$$\n",
    "\\frac{True　pos}{actual　pos} = \\frac{True　pos}{True　pos+ False　neg} \\tag5\n",
    "$$\n",
    "\n",
    "在前面我们提到，将误差转变为一个单一的数值非常重要，因为这样我们才能方便的比较不同算法之间的优劣。现在我们有precision和recall两个衡量标准，我们需要权衡两者。如果用Logistic回归模型预测病人是否患癌症，考虑下面的情况：  \n",
    ">假设考虑到一个正常人如果误判为癌症，将会承受不必要的心理和生理压力，所以我们要有很大把握才预测一个病人患癌症(y=1)。那么一种方式就是提高阈值(threshold)，不妨设我们将阈值提高到0.7，即：  \n",
    "$$\n",
    "Predict 1　　if: h_{\\theta}(x)\\ge 0.7\\\\\n",
    "Predict 0　　if: h_{\\theta}(x)\\lt 0.7\n",
    "$$\n",
    "\n",
    "在这种情况下，我们将会有较高的precision，但是recall将会变低。  \n",
    ">假设考虑到一个已经患癌症的病人如果误判为没有患癌症，那么病人可能将因不能及时治疗而失去宝贵生命，所以我们想要避免错过癌症患者的一种方式就是降低阙值，假设降低到0.3, 即：\n",
    "$$\n",
    "Predict 1　　if: h_{\\theta}(x)\\ge 0.3\\\\\n",
    "Predict 0　　if: h_{\\theta}(x)\\lt 0.3\n",
    "$$\n",
    "\n",
    "在这种情况下，将得到较高的recall，但是precision将会下降。  \n",
    "为了将precision和recal转变为一个单一数值，我们引入了$F_1 \\text{scale} （调和平均数）: $ $$F_1 = 2\\frac{PR}{P+R}  \\tag5 $$  \n",
    "$F_1$越大，表明算法效果越好。\n",
    ">例：有三个不同算法的Precision和Recall，那到底选择哪个算法好呢？\n",
    "\n",
    "|Precision  | Recall|F1|\n",
    "|:-----:|:-----:|:---:|\n",
    "|Algorithm1 | 0.5   |0.444|\n",
    "|Algorithm2 | 0.7   |0.175|\n",
    "|Algorithm3 | 0.02  |0.039|\n",
    ">可以看到 A1的F1值最大，故选择A1效果最好。\n",
    "\n",
    ">>调和平均数具有以下几个主要特点（来自百度百科）：\n",
    "- 调和平均数易受极端值的影响，且受极小值的影响比受极大值的影响更大。\n",
    "- 只要有一个标志值为0，就不能计算调和平均数。\n",
    "- 当组距数列有开口组时，其组中值即使按相邻组距计算，假定性也很大，这时的调和平均数的代表性很不可靠。\n",
    "- 调和平均数应用的范围较小。在实际中，往往由于缺乏总体单位数的资料而不能直接计算算术平均数，这时需用调和平均法来求得平均数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.bilibili.com/video/av9912938/index_64.html#page=64  \n",
    "https://www.bilibili.com/video/av9912938/index_65.html#page=65  \n",
    "https://www.bilibili.com/video/av9912938/index_66.html#page=66  \n",
    "https://www.bilibili.com/video/av9912938/index_67.html#page=67  \n",
    "https://www.bilibili.com/video/av9912938/index_68.html#page=68  \n",
    "http://blog.csdn.net/qq_27008079/article/details/72511079"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
